import os
import json
import logging

logging.basicConfig(
    level=logging.DEBUG,
    format="%(asctime)s [%(levelname)s] [%(filename)s:%(lineno)d] %(message)s",
)

# ç¡®å®šä¸ƒä¸‹å•è¯æ•°æ®çš„è·¯å¾„
word_data_file = "data/ä¸ƒä¸‹/7ä¸‹è‹±è¯­å•è¯.json"
result_path = "result/all"
# word_analysis_dir = "data/all/global-words.json"
article_dir = "result/ä¸ƒä¸‹_articles"
image_file_path = "https://word.vxiaozhi.com/imgs/word_imgs"

with open(word_data_file, "r", encoding="utf-8") as f:
    words_data = json.load(f)

unit_list = sorted(set([word["unit"] for word in words_data]))

with open("DictionaryByGPT4.json", "r", encoding="utf-8") as f:
    DictionaryByGPT4 = json.load(f)

# words_data
# [{
#   "unit": "Unit1 Animal Friends",
#   "num": 1,
#   "word": "fox",
#   "phonetic_symbol": "[fÉ’ks]",
#   "mean": "n.ç‹ç‹¸"
# }],


for target_unit in unit_list:
    print("ğŸš€ ~ file: ä¸ƒä¸‹1.py:31 ~ target_unit:", target_unit)
    target_words = [word for word in words_data if word["unit"] == target_unit]
    # print("ğŸš€ ~ file: ä¸ƒä¸‹1.py:32 ~ target_words:", target_words)
    # print(
    #     "ğŸš€ ~ file: ä¸ƒä¸‹1.py:32 ~ target_words:",
    #     [word["word"] for word in target_words],
    # )

    # å‡†å¤‡Markdownå†…å®¹
    content = f"""# 2025äººæ•™ç‰ˆè‹±è¯­è¯æ±‡é‡Šæ„åŠ©è®°(DeepSeekç‰ˆ) ä¸ƒä¸‹ {target_unit}

> (ä½¿ç”¨ DeepSeek æä¾›å•è¯çš„è¯ä¹‰ã€è¯æ ¹ã€ä¾‹å¥ã€è¾…åŠ©è®°å¿†ã€åŠ©è®°å›¾åƒç­‰ä¿¡æ¯ã€‚)

"""

    # https://www.vxiaozhi.com/imgs/cet4/a/abandon.jpg

    article_file_path = os.path.join(article_dir, f"{target_unit}.md")
    for cur_word in target_words:
        word = cur_word.get("word")
        print("ğŸš€ ~ file: ä¸ƒä¸‹1.py:57 ~ word:", word)
        content += f"""## {word} - {cur_word["mean"]}

### è¯¾æœ¬é‡Šä¹‰

**åºå·**ï¼š{cur_word["num"]}
**éŸ³æ ‡**ï¼š{cur_word["phonetic_symbol"]}
**é‡Šä¹‰**ï¼š{cur_word["mean"]}
"""
        # è¯»å–å•è¯åˆ†ææ•°æ®
        word_json_path = os.path.join(result_path, word[0], f"{word}.json")
        word_image_path = (f"{image_file_path}/{word[0]}/{word}.jpg").lower()
        # print("ğŸš€ ~ file: ä¸ƒä¸‹1.py:62 ~ word_json_path:", word_json_path)
        if os.path.exists(word_json_path):
            with open(word_json_path, "r", encoding="utf-8") as f:
                words_ana_data = json.load(f)
            analysis = words_ana_data.get("analysis", "")
            draw_explain = words_ana_data.get("draw_explain", "")
            # print("ğŸš€ ~ file: ä¸ƒä¸‹1.py:67 ~ draw_prompt:", analysis)
            content += f"""
{analysis}

### åŠ©è®°å›¾åƒ

{draw_explain}

![{word}]({word_image_path})

"""

        else:
            DictionaryByGPT4_flag = 0
            for gpt4word in DictionaryByGPT4:
                if gpt4word["word"] == cur_word["word"]:
                    content += f"""
[FROM DictionaryByGPT4:]
{gpt4word["content"]}
"""
                    DictionaryByGPT4_flag = 1
                    break
            if DictionaryByGPT4_flag == 0:
                """æ‰¾ä¸åˆ°æ—¶"""
                print("[å¾…å®Œå–„]")
                content += """
[å¾…å®Œå–„]
"""

    # ç”ŸæˆMarkdownæ–‡ä»¶
    # å†™å…¥æ–‡ä»¶
    with open(article_file_path, "w", encoding="utf-8") as f:
        f.write(content)
        f.write(
            """ \n\n ## æ„Ÿè°¢ä»¥ä¸‹å¼€æºé¡¹ç›® \n\n- [vocabulary-book-by-deepseek](https://github.com/vxiaozhi/vocabulary-book-by-deepseek) \n\n- [å°æ™ºæ™–çš„AIå•è¯åº“](https://word.vxiaozhi.com/)"""
        )

# for unit in unit_list:
#     # åˆ›å»ºå•è¯åˆ†æçš„ç›®å½•
#     unit_dir = os.path.join(word_analysis_dir, unit)
#     if not os.path.exists(unit_dir):
#         os.makedirs(unit_dir)

#     # éå†æ–‡ç« ç›®å½•ï¼Œæ‰¾åˆ°ä»¥ unit ä¸ºå‰ç¼€çš„æ–‡ä»¶
#     for filename in os.listdir(article_dir):
#         if filename.startswith(unit):
